{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The project has evolved. The CSV files are now in the olist.db database. For the project with the old schema between the CSV files, it might be useful to create a mapping between the old CSV files and the database tables, as well as the common keys between the tables. https://drive.google.com/file/d/1cC1h5ZiakQMM6Ut9Hqf13r-jTpMHV8d5/view?usp=sharing  ",
   "id": "e8236cb396d6bd52"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Schema of liaison between data when data where csv files see https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce",
   "id": "a4a75974a3adcc62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![data_schema.PNG](../data/data_schema.PNG)\n",
   "id": "ccfdf16ff715557f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here is a mapping table in text format between the CSV files and the tables in `olist.db`, including the identical keys between tables when they exist:\n",
    "\n",
    "| CSV File                               | SQLite Table       | Identical Keys                            |\n",
    "|----------------------------------------|--------------------|-------------------------------------------|\n",
    "| olist_customers_dataset.csv            | customers          | customer_id, customer_zip_code_prefix     |\n",
    "| olist_geolocation_dataset.csv          | geoloc             | geolocation_zip_code_prefix               |\n",
    "| olist_order_items_dataset.csv          | order_items        | order_id, product_id, seller_id           |\n",
    "| olist_order_payments_dataset.csv       | order_pymts        | order_id                                  |\n",
    "| olist_order_reviews_dataset.csv        | order_reviews      | order_id                                  |\n",
    "| olist_orders_dataset.csv               | orders             | customer_id, order_id                     |\n",
    "| olist_products_dataset.csv             | products           | product_id                                |\n",
    "| olist_sellers_dataset.csv              | sellers            | seller_id, seller_zip_code_prefix         |\n",
    "| product_category_name_translation.csv  | translation        | product_category_name                     |\n",
    "\n",
    "### Mapping Details\n",
    "\n",
    "1. **olist_customers_dataset.csv -> customers**\n",
    "   - Identical Keys: `customer_id`, `customer_zip_code_prefix`\n",
    "\n",
    "2. **olist_geolocation_dataset.csv -> geoloc**\n",
    "   - Identical Keys: `geolocation_zip_code_prefix`\n",
    "\n",
    "3. **olist_order_items_dataset.csv -> order_items**\n",
    "   - Identical Keys: `order_id`, `product_id`, `seller_id`\n",
    "\n",
    "4. **olist_order_payments_dataset.csv -> order_pymts**\n",
    "   - Identical Keys: `order_id`\n",
    "\n",
    "5. **olist_order_reviews_dataset.csv -> order_reviews**\n",
    "   - Identical Keys: `order_id`\n",
    "\n",
    "6. **olist_orders_dataset.csv -> orders**\n",
    "   - Identical Keys: `customer_id`, `order_id`\n",
    "\n",
    "7. **olist_products_dataset.csv -> products**\n",
    "   - Identical Keys: `product_id`\n",
    "\n",
    "8. **olist_sellers_dataset.csv -> sellers**\n",
    "   - Identical Keys: `seller_id`, `seller_zip_code_prefix`\n",
    "\n",
    "9. **product_category_name_translation.csv -> translation**\n",
    "   - Identical Keys: `product_category_name`\n",
    "\n",
    "### Explanation\n",
    "- Identical keys are used to establish relationships between different tables, thus facilitating the necessary joins for complex queries.\n",
    "- For example, `order_id` is a common key between the tables `orders`, `order_pymts`, `order_reviews`, and `order_items`, allowing the linking of order information, payment, reviews, and order items.\n",
    "\n",
    "This mapping table can serve as a reference to understand how the data from the CSV files is structured in the `olist.db` database and how they can be joined to answer analytical questions."
   ],
   "id": "e7c62d3056d4c224"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Olist E-Commerce connection to the database check",
   "id": "a0d5dda00b2e6cc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T16:56:13.821562Z",
     "start_time": "2024-07-24T16:56:13.797026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# Relative path to the database\n",
    "db_path = os.path.join('..', 'data', 'olist.db')\n",
    "\n",
    "if os.path.exists(db_path):\n",
    "    print(\"Connecting to the database...\")\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    print(\"Database connected.\")\n",
    "    \n",
    "    query = \"SELECT COUNT(*) FROM orders;\"\n",
    "    try:\n",
    "        data = pd.read_sql(query, conn)\n",
    "        print(\"Total number of rows in orders table:\", data.iloc[0, 0])\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "    finally:\n",
    "        conn.close()\n",
    "        print(\"Database connection closed.\")\n",
    "else:\n",
    "    print(\"The file does not exist at the specified location:\", db_path)\n",
    "\n"
   ],
   "id": "d51e48109c77fa88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the database...\n",
      "Database connected.\n",
      "Total number of rows in orders table: 99441\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d28929ddd889c526"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Inspecting the Database Schema",
   "id": "11b4ae36d392d9a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T16:56:13.962839Z",
     "start_time": "2024-07-24T16:56:13.895708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# Relative path to the database\n",
    "db_path = os.path.join('..', 'data', 'olist.db')\n",
    "\n",
    "if os.path.exists(db_path):\n",
    "    print(\"Connecting to the database...\")\n",
    "    \n",
    "    # Create a connection to the database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    print(\"Database connected.\")\n",
    "    \n",
    "    try:\n",
    "        # List all tables\n",
    "        tables_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "        tables = pd.read_sql(tables_query, conn)\n",
    "        print(\"Tables in the database:\")\n",
    "        print(tables)\n",
    "\n",
    "        # Inspect schema of the relevant tables\n",
    "        for table in tables['name']:\n",
    "            schema_query = f\"PRAGMA table_info({table});\"\n",
    "            schema = pd.read_sql(schema_query, conn)\n",
    "            print(f\"Schema of {table}:\")\n",
    "            print(schema)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        conn.close()\n",
    "        print(\"Database connection closed.\")\n",
    "else:\n",
    "    print(\"The file does not exist at the specified location:\", db_path)\n",
    "\n"
   ],
   "id": "bc8840325bf30abf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the database...\n",
      "Database connected.\n",
      "Tables in the database:\n",
      "            name\n",
      "0      customers\n",
      "1         geoloc\n",
      "2    order_items\n",
      "3    order_pymts\n",
      "4  order_reviews\n",
      "5         orders\n",
      "6       products\n",
      "7        sellers\n",
      "8    translation\n",
      "Schema of customers:\n",
      "   cid                      name    type  notnull dflt_value  pk\n",
      "0    0                     index  BIGINT        0       None   0\n",
      "1    1               customer_id    TEXT        0       None   0\n",
      "2    2        customer_unique_id    TEXT        0       None   0\n",
      "3    3  customer_zip_code_prefix  BIGINT        0       None   0\n",
      "4    4             customer_city    TEXT        0       None   0\n",
      "5    5            customer_state    TEXT        0       None   0\n",
      "Schema of geoloc:\n",
      "   cid                         name    type  notnull dflt_value  pk\n",
      "0    0                        index  BIGINT        0       None   0\n",
      "1    1  geolocation_zip_code_prefix  BIGINT        0       None   0\n",
      "2    2              geolocation_lat   FLOAT        0       None   0\n",
      "3    3              geolocation_lng   FLOAT        0       None   0\n",
      "4    4             geolocation_city    TEXT        0       None   0\n",
      "5    5            geolocation_state    TEXT        0       None   0\n",
      "Schema of order_items:\n",
      "   cid                 name    type  notnull dflt_value  pk\n",
      "0    0                index  BIGINT        0       None   0\n",
      "1    1             order_id    TEXT        0       None   0\n",
      "2    2        order_item_id  BIGINT        0       None   0\n",
      "3    3           product_id    TEXT        0       None   0\n",
      "4    4            seller_id    TEXT        0       None   0\n",
      "5    5  shipping_limit_date    TEXT        0       None   0\n",
      "6    6                price   FLOAT        0       None   0\n",
      "7    7        freight_value   FLOAT        0       None   0\n",
      "Schema of order_pymts:\n",
      "   cid                  name    type  notnull dflt_value  pk\n",
      "0    0                 index  BIGINT        0       None   0\n",
      "1    1              order_id    TEXT        0       None   0\n",
      "2    2    payment_sequential  BIGINT        0       None   0\n",
      "3    3          payment_type    TEXT        0       None   0\n",
      "4    4  payment_installments  BIGINT        0       None   0\n",
      "5    5         payment_value   FLOAT        0       None   0\n",
      "Schema of order_reviews:\n",
      "   cid                     name    type  notnull dflt_value  pk\n",
      "0    0                    index  BIGINT        0       None   0\n",
      "1    1                review_id    TEXT        0       None   0\n",
      "2    2                 order_id    TEXT        0       None   0\n",
      "3    3             review_score  BIGINT        0       None   0\n",
      "4    4     review_comment_title    TEXT        0       None   0\n",
      "5    5   review_comment_message    TEXT        0       None   0\n",
      "6    6     review_creation_date    TEXT        0       None   0\n",
      "7    7  review_answer_timestamp    TEXT        0       None   0\n",
      "Schema of orders:\n",
      "   cid                           name    type  notnull dflt_value  pk\n",
      "0    0                          index  BIGINT        0       None   0\n",
      "1    1                       order_id    TEXT        0       None   0\n",
      "2    2                    customer_id    TEXT        0       None   0\n",
      "3    3                   order_status    TEXT        0       None   0\n",
      "4    4       order_purchase_timestamp    TEXT        0       None   0\n",
      "5    5              order_approved_at    TEXT        0       None   0\n",
      "6    6   order_delivered_carrier_date    TEXT        0       None   0\n",
      "7    7  order_delivered_customer_date    TEXT        0       None   0\n",
      "8    8  order_estimated_delivery_date    TEXT        0       None   0\n",
      "Schema of products:\n",
      "   cid                        name    type  notnull dflt_value  pk\n",
      "0    0                       index  BIGINT        0       None   0\n",
      "1    1                  product_id    TEXT        0       None   0\n",
      "2    2       product_category_name    TEXT        0       None   0\n",
      "3    3         product_name_lenght   FLOAT        0       None   0\n",
      "4    4  product_description_lenght   FLOAT        0       None   0\n",
      "5    5          product_photos_qty   FLOAT        0       None   0\n",
      "6    6            product_weight_g   FLOAT        0       None   0\n",
      "7    7           product_length_cm   FLOAT        0       None   0\n",
      "8    8           product_height_cm   FLOAT        0       None   0\n",
      "9    9            product_width_cm   FLOAT        0       None   0\n",
      "Schema of sellers:\n",
      "   cid                    name    type  notnull dflt_value  pk\n",
      "0    0                   index  BIGINT        0       None   0\n",
      "1    1               seller_id    TEXT        0       None   0\n",
      "2    2  seller_zip_code_prefix  BIGINT        0       None   0\n",
      "3    3             seller_city    TEXT        0       None   0\n",
      "4    4            seller_state    TEXT        0       None   0\n",
      "Schema of translation:\n",
      "   cid                           name    type  notnull dflt_value  pk\n",
      "0    0                          index  BIGINT        0       None   0\n",
      "1    1          product_category_name    TEXT        0       None   0\n",
      "2    2  product_category_name_english    TEXT        0       None   0\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Checking for Common Values in Key Columns",
   "id": "97edd3f0bda5c380"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T16:56:19.390485Z",
     "start_time": "2024-07-24T16:56:13.965839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# Relative path to the database\n",
    "db_path = os.path.join('..', 'data', 'olist.db')\n",
    "\n",
    "# Function to execute SQL queries and return DataFrames\n",
    "def execute_query(query):\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        return pd.read_sql(query, conn)\n",
    "\n",
    "# Function to get unique values of a column\n",
    "def get_unique_column_values(table, column):\n",
    "    query = f\"SELECT DISTINCT {column} FROM {table}\"\n",
    "    df = execute_query(query)\n",
    "    return set(df[column].values)\n",
    "\n",
    "# List of tables and columns to check\n",
    "tables_columns = {\n",
    "    'customers': ['customer_id', 'customer_unique_id', 'customer_zip_code_prefix'],\n",
    "    'geoloc': ['geolocation_zip_code_prefix'],\n",
    "    'order_items': ['order_id', 'product_id', 'seller_id'],\n",
    "    'order_pymts': ['order_id'],\n",
    "    'order_reviews': ['order_id', 'review_id'],\n",
    "    'orders': ['order_id', 'customer_id'],\n",
    "    'products': ['product_id'],\n",
    "    'sellers': ['seller_id', 'seller_zip_code_prefix'],\n",
    "    'translation': ['product_category_name'],\n",
    "}\n",
    "\n",
    "# Function to compare columns and check for common values\n",
    "def compare_columns(tables_columns):\n",
    "    common_values_found = False\n",
    "    columns_to_compare = {}\n",
    "    \n",
    "    for table, columns in tables_columns.items():\n",
    "        for column in columns:\n",
    "            columns_to_compare[f\"{table}.{column}\"] = get_unique_column_values(table, column)\n",
    "    \n",
    "    keys = list(columns_to_compare.keys())\n",
    "    \n",
    "    for i in range(len(keys)):\n",
    "        table_column1 = keys[i]\n",
    "        values1 = columns_to_compare[table_column1]\n",
    "        for j in range(i + 1, len(keys)):\n",
    "            table_column2 = keys[j]\n",
    "            values2 = columns_to_compare[table_column2]\n",
    "            common_values = values1.intersection(values2)\n",
    "            if common_values:\n",
    "                print(f\"Common values found between {table_column1} and {table_column2}:\")\n",
    "                print(f\"Number of common values: {len(common_values)}\")\n",
    "                print(f\"Sample common values: {list(common_values)[:5]}\")  # Print only the first 5 common values as a sample\n",
    "                common_values_found = True\n",
    "    \n",
    "    if not common_values_found:\n",
    "        print(\"No common values found between the specified columns of different tables.\")\n",
    "\n",
    "# Specific validation for customer_id, order_id, and customer_unique_id\n",
    "def compare_specific_columns(columns_to_compare):\n",
    "    special_cases = [\n",
    "        ('customers.customer_id', 'orders.order_id'),\n",
    "        ('customers.customer_id', 'customers.customer_unique_id'),\n",
    "        ('customers.customer_unique_id', 'orders.order_id')\n",
    "    ]\n",
    "    \n",
    "    for case in special_cases:\n",
    "        table_column1, table_column2 = case\n",
    "        values1 = columns_to_compare.get(table_column1, set())\n",
    "        values2 = columns_to_compare.get(table_column2, set())\n",
    "        common_values = values1.intersection(values2)\n",
    "        if common_values:\n",
    "            print(f\"Common values found between {table_column1} and {table_column2}: {common_values}\")\n",
    "        else:\n",
    "            print(f\"No common values found between {table_column1} and {table_column2}\")    \n",
    "            \n",
    "\n",
    "# Include in main function\n",
    "def compare_columns(tables_columns):\n",
    "    common_values_found = False\n",
    "    columns_to_compare = {}\n",
    "    \n",
    "    for table, columns in tables_columns.items():\n",
    "        for column in columns:\n",
    "            columns_to_compare[f\"{table}.{column}\"] = get_unique_column_values(table, column)\n",
    "    \n",
    "    keys = list(columns_to_compare.keys())\n",
    "    \n",
    "    for i in range(len(keys)):\n",
    "        table_column1 = keys[i]\n",
    "        values1 = columns_to_compare[table_column1]\n",
    "        for j in range(i + 1, len(keys)):\n",
    "            table_column2 = keys[j]\n",
    "            values2 = columns_to_compare[table_column2]\n",
    "            common_values = values1.intersection(values2)\n",
    "            if common_values:\n",
    "                print(f\"Common values found between {table_column1} and {table_column2}:\")\n",
    "                print(f\"Number of common values: {len(common_values)}\")\n",
    "                print(f\"Sample common values: {list(common_values)[:5]}\")  # Print only the first 5 common values as a sample\n",
    "                common_values_found = True\n",
    "    \n",
    "    # Specific validation\n",
    "    if compare_specific_columns(columns_to_compare):\n",
    "        common_values_found = True\n",
    "    \n",
    "    if not common_values_found:\n",
    "        print(\"No common values found between the specified columns of different tables.\")\n",
    "\n",
    "# Execute the column comparison\n",
    "compare_columns(tables_columns)\n"
   ],
   "id": "f489e83e3b101b4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common values found between customers.customer_id and orders.customer_id:\n",
      "Number of common values: 99441\n",
      "Sample common values: ['9fe0cd1d9873dff9f76b9dd37009dc5a', '3ae0909507f3aff8f82173639d398da2', 'cf5c87f52f4f9d68b80bbaaea6afcb67', '0f684a3f14d10efbcb72b61453fc70d8', '30ff74ba6ed04c0069481436021bc4aa']\n",
      "Common values found between customers.customer_zip_code_prefix and geoloc.geolocation_zip_code_prefix:\n",
      "Number of common values: 14837\n",
      "Sample common values: [65540, 65550, 65560, 98335, 98338]\n",
      "Common values found between customers.customer_zip_code_prefix and sellers.seller_zip_code_prefix:\n",
      "Number of common values: 2162\n",
      "Sample common values: [81925, 81930, 8215, 8220, 8223]\n",
      "Common values found between geoloc.geolocation_zip_code_prefix and sellers.seller_zip_code_prefix:\n",
      "Number of common values: 2239\n",
      "Sample common values: [81925, 81930, 8215, 8220, 8223]\n",
      "Common values found between order_items.order_id and order_pymts.order_id:\n",
      "Number of common values: 98665\n",
      "Sample common values: ['8b5c910ccad3b27e2876ad9eb90bbb53', 'd7ae32c7a5b1f93a80e672ce4fe7d7f5', '2cec6c78bc16c3954626e44c56219686', '1235febb7f139ccf94d83ff97ae8e889', '075867c84468363ed47de8b38d904253']\n",
      "Common values found between order_items.order_id and order_reviews.order_id:\n",
      "Number of common values: 97917\n",
      "Sample common values: ['8b5c910ccad3b27e2876ad9eb90bbb53', 'd7ae32c7a5b1f93a80e672ce4fe7d7f5', '2cec6c78bc16c3954626e44c56219686', '1235febb7f139ccf94d83ff97ae8e889', '075867c84468363ed47de8b38d904253']\n",
      "Common values found between order_items.order_id and orders.order_id:\n",
      "Number of common values: 98666\n",
      "Sample common values: ['8b5c910ccad3b27e2876ad9eb90bbb53', 'd7ae32c7a5b1f93a80e672ce4fe7d7f5', '2cec6c78bc16c3954626e44c56219686', '1235febb7f139ccf94d83ff97ae8e889', '075867c84468363ed47de8b38d904253']\n",
      "Common values found between order_items.product_id and products.product_id:\n",
      "Number of common values: 32951\n",
      "Sample common values: ['4ae1bd4115a0ea08489ff7e821ddc4e5', '658fc236815a88341f858edcdb0ec78a', 'e5b1f66dbce509c58fa37ff08428f91d', 'd7a023eecac412d29d49735e9e9b629f', '1da3e4356495511914d62ce5385f7122']\n",
      "Common values found between order_items.seller_id and sellers.seller_id:\n",
      "Number of common values: 3095\n",
      "Sample common values: ['c731d18cea9bf687ffee82a241c25b11', '688756f717c462a206ad854c5027a64a', 'c6a7539d424a8402232c2228d7a03c5e', '7fdb0720c8d7c9075538b365dc8c3a22', '709e16e2b25c7474d980076c6bfc4806']\n",
      "Common values found between order_pymts.order_id and order_reviews.order_id:\n",
      "Number of common values: 98672\n",
      "Sample common values: ['8b5c910ccad3b27e2876ad9eb90bbb53', 'd7ae32c7a5b1f93a80e672ce4fe7d7f5', '1235febb7f139ccf94d83ff97ae8e889', '2cec6c78bc16c3954626e44c56219686', '075867c84468363ed47de8b38d904253']\n",
      "Common values found between order_pymts.order_id and orders.order_id:\n",
      "Number of common values: 99440\n",
      "Sample common values: ['8b5c910ccad3b27e2876ad9eb90bbb53', 'd7ae32c7a5b1f93a80e672ce4fe7d7f5', '1235febb7f139ccf94d83ff97ae8e889', '2cec6c78bc16c3954626e44c56219686', '075867c84468363ed47de8b38d904253']\n",
      "Common values found between order_reviews.order_id and orders.order_id:\n",
      "Number of common values: 98673\n",
      "Sample common values: ['8b5c910ccad3b27e2876ad9eb90bbb53', 'd7ae32c7a5b1f93a80e672ce4fe7d7f5', '1235febb7f139ccf94d83ff97ae8e889', '2cec6c78bc16c3954626e44c56219686', '075867c84468363ed47de8b38d904253']\n",
      "No common values found between customers.customer_id and orders.order_id\n",
      "No common values found between customers.customer_id and customers.customer_unique_id\n",
      "No common values found between customers.customer_unique_id and orders.order_id\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Key Observations\n",
    "\n",
    "1. **Expected Foreign Key Relationships**:\n",
    "    - `order_items.order_id`, `order_pymts.order_id`, `order_reviews.order_id`, and `orders.order_id`: High numbers of common values, indicating expected foreign key relationships.\n",
    "    - `order_items.product_id` and `products.product_id`: 32951 common values, indicating a correct relationship.\n",
    "    - `order_items.seller_id` and `sellers.seller_id`: 3095 common values, indicating a correct relationship.\n",
    "\n",
    "2. **Zip Code Relationships**:\n",
    "    - `customers.customer_zip_code_prefix` and `geoloc.geolocation_zip_code_prefix`: 14837 common values.\n",
    "    - `customers.customer_zip_code_prefix` and `sellers.seller_zip_code_prefix`: 2162 common values.\n",
    "    - `geoloc.geolocation_zip_code_prefix` and `sellers.seller_zip_code_prefix`: 2239 common values.\n",
    "\n",
    "### Specific Validation\n",
    "\n",
    "1. **No Common Values**:\n",
    "    - `customers.customer_id` and `orders.order_id`: No common values found.\n",
    "    - `customers.customer_id` and `customers.customer_unique_id`: No common values found.\n",
    "    - `customers.customer_unique_id` and `orders.order_id`: No common values found.\n",
    "\n",
    "This indicates that the `customer_id` in the `customers` table is properly distinguished from `order_id` in the `orders` table and `customer_unique_id` in the `customers` table. This is the expected result and confirms that there are no unexpected overlaps between these IDs.\n",
    "\n",
    "-  Common values found between customers.customer_id and orders.customer_id: Number of common values: 99441 => same values so"
   ],
   "id": "abad93b3d38bee8a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Query to Display a Few Rows and the Date Format",
   "id": "cd03086b50af2d4d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T16:56:19.405968Z",
     "start_time": "2024-07-24T16:56:19.392682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# Relative path to the database\n",
    "db_path = os.path.join('..', 'data', 'olist.db')\n",
    "\n",
    "if os.path.exists(db_path):\n",
    "    print(\"Connecting to the database...\")\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    print(\"Database connected.\")\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        order_id,\n",
    "        customer_id,\n",
    "        order_status,\n",
    "        order_purchase_timestamp\n",
    "    FROM orders\n",
    "    LIMIT 5;\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_sql(query, conn)\n",
    "        print(\"Sample rows from orders table:\")\n",
    "        print(data)  # Display sample rows to check date format\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "    finally:\n",
    "        conn.close()\n",
    "        print(\"Database connection closed.\")\n",
    "else:\n",
    "    print(\"The file does not exist at the specified location:\", db_path)\n"
   ],
   "id": "67d995ae11d4105d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the database...\n",
      "Database connected.\n",
      "Sample rows from orders table:\n",
      "                           order_id                       customer_id  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
      "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
      "\n",
      "  order_status order_purchase_timestamp  \n",
      "0    delivered      2017-10-02 10:56:33  \n",
      "1    delivered      2018-07-24 20:41:37  \n",
      "2    delivered      2018-08-08 08:38:49  \n",
      "3    delivered      2017-11-18 19:28:06  \n",
      "4    delivered      2018-02-13 21:18:39  \n",
      "Database connection closed.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Query to Display the Current Date in order_purchase_timestamp Format",
   "id": "7d3fff2c73d5560d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T16:56:19.420998Z",
     "start_time": "2024-07-24T16:56:19.407970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# Relative path to the database\n",
    "db_path = os.path.join('..', 'data', 'olist.db')\n",
    "\n",
    "if os.path.exists(db_path):\n",
    "    print(\"Connecting to the database...\")\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    print(\"Database connected.\")\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT strftime('%Y-%m-%d %H:%M:%S', 'now') AS current_date;\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_sql(query, conn)\n",
    "        print(\"Current date (formatted):\")\n",
    "        print(data)  # Display the current date to ensure it's being calculated correctly\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "    finally:\n",
    "        conn.close()\n",
    "        print(\"Database connection closed.\")\n",
    "else:\n",
    "    print(\"The file does not exist at the specified location:\", db_path)\n"
   ],
   "id": "789dee101efc8dae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the database...\n",
      "Database connected.\n",
      "Current date (formatted):\n",
      "          current_date\n",
      "0  2024-07-24 16:56:19\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.Recent Orders with at Least 3 Days of Delay (Excluding Canceled Orders) for Orders Less Than 90 Days Old (latest date for order_purchase_timestamp is the latest date in the database)",
   "id": "f8a332cb2ff68c1d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Explanation of the Query\n",
    "1. **Recent Orders**: The query filters the orders based on the purchase timestamp to select only the recent orders placed in the last 90 days.\n",
    "2. **Order Status**: It excludes the canceled orders by checking the order status.\n",
    "3. **Delay Calculation**: The delay in delivery is calculated by finding the difference in days between the delivered customer date and the estimated delivery date.\n",
    "4. **Common Table Expression (CTE)**: The query uses a Common Table Expression (CTE) named `RelevantOrders` to filter the orders based on the conditions specified.\n",
    "5. **Result Columns**: The final result includes the `order_id`, `customer_id`, `order_status`, `order_purchase_timestamp`, `order_delivered_customer_date`, and `delay_days` columns for the selected orders.\n",
    "6. **Data Loading**: The query result is loaded into a pandas DataFrame for further analysis and display.\n",
    "7. **Display**: The first few rows of the resulting DataFrame are displayed to show the recent orders with at least 3 days of delay.\n",
    "8. **Context**: The query considers the date range issue and provides additional information if no data is available due to older dates in the database."
   ],
   "id": "4ba3f6cb18c279d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T16:56:19.687971Z",
     "start_time": "2024-07-24T16:56:19.426004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# Relative path to the database\n",
    "db_path = os.path.join('..', 'data', 'olist.db')\n",
    "\n",
    "# Function to execute SQL queries and return results as a pandas DataFrame\n",
    "def execute_query(query):\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        return pd.read_sql(query, conn)\n",
    "\n",
    "# Check if the file exists before attempting to connect\n",
    "if os.path.exists(db_path):\n",
    "    print(\"Connecting to the database...\")\n",
    "    \n",
    "    try:\n",
    "        # Create a connection to the database\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        print(\"Database connected.\")\n",
    "\n",
    "        # Query Recent Orders with at Least 3 Days of Delay (Excluding Canceled Orders) for Orders Less Than 90 Days Old (latest date for order_purchase_timestamp is the latest date in the database)\n",
    "        combined_query = \"\"\"\n",
    "        WITH LatestDate AS (\n",
    "            SELECT MAX(order_purchase_timestamp) AS latest_order_date\n",
    "            FROM orders\n",
    "        ),\n",
    "        RecentOrders AS (\n",
    "            SELECT \n",
    "                order_id,\n",
    "                customer_id,\n",
    "                order_status,\n",
    "                order_purchase_timestamp,\n",
    "                order_delivered_customer_date,\n",
    "                julianday(order_delivered_customer_date) - julianday(order_estimated_delivery_date) AS delay_days\n",
    "            FROM orders, LatestDate\n",
    "            WHERE \n",
    "                order_status <> 'canceled' \n",
    "                AND order_purchase_timestamp >= datetime(LatestDate.latest_order_date, '-90 days')\n",
    "        )\n",
    "        SELECT\n",
    "            (SELECT latest_order_date FROM LatestDate) AS latest_order_date,\n",
    "            (SELECT COUNT(*) FROM RecentOrders) AS recent_orders_count,\n",
    "            order_id,\n",
    "            customer_id,\n",
    "            order_status,\n",
    "            order_purchase_timestamp,\n",
    "            order_delivered_customer_date,\n",
    "            delay_days\n",
    "        FROM RecentOrders\n",
    "        WHERE delay_days >= 3;\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the combined query and load data into a DataFrame\n",
    "        data = execute_query(combined_query)\n",
    "        \n",
    "        # Extract and print the latest order date\n",
    "        latest_order_date = data['latest_order_date'][0]\n",
    "        print(f\"Latest order purchase date in the database: {latest_order_date}\")\n",
    "        \n",
    "        # Extract and print the count of recent orders\n",
    "        recent_orders_count = data['recent_orders_count'][0]\n",
    "        print(f\"Number of recent orders in the last 90 days: {recent_orders_count}\")\n",
    "\n",
    "        # Drop the extra columns used for display purposes\n",
    "        data = data.drop(columns=['latest_order_date', 'recent_orders_count'])\n",
    "\n",
    "        if recent_orders_count == 0 or data.empty:\n",
    "            print(\"No data available for recent orders with at least 3 days of delay (excluding canceled orders) for orders less than 90 days old.\")\n",
    "        else:\n",
    "            print(\"Query executed successfully.\")\n",
    "            print(data.shape)  # Display the shape of the result\n",
    "            print(data.head())  # Display the first few rows of the result\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        conn.close()\n",
    "        print(\"Database connection closed.\")\n",
    "else:\n",
    "    print(\"The file does not exist at the specified location:\", db_path)\n"
   ],
   "id": "1f8944db07664e27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the database...\n",
      "Database connected.\n",
      "Latest order purchase date in the database: 2018-10-17 17:30:18\n",
      "Number of recent orders in the last 90 days: 9405\n",
      "Query executed successfully.\n",
      "(307, 6)\n",
      "                           order_id                       customer_id  \\\n",
      "0  cfa4fa27b417971e86d8127cb688712f  7093250e1741ebbed41f0cc552025fd6   \n",
      "1  234c056c50619f48da64f731c48242b4  44e460a655f7154ccd9faa4dbbbaf68a   \n",
      "2  7f579e203c931f3e8410103359c6d523  d665be250d1c687c58fdea61a9b55a58   \n",
      "3  cb6e441ff2ef574ce08d3709426f88ec  4fb843d304c57182d4aa27bb39ca592b   \n",
      "4  03720fdc92032ee4abd471d172006ab0  116458665bac0ff47d5e87f65e8ec681   \n",
      "\n",
      "  order_status order_purchase_timestamp order_delivered_customer_date  \\\n",
      "0    delivered      2018-08-16 09:44:23           2018-08-29 01:41:41   \n",
      "1    delivered      2018-08-14 14:49:15           2018-09-01 18:14:42   \n",
      "2    delivered      2018-08-02 18:09:27           2018-08-13 20:11:47   \n",
      "3    delivered      2018-08-08 19:27:03           2018-08-18 01:11:58   \n",
      "4    delivered      2018-08-05 21:34:54           2018-08-21 00:11:52   \n",
      "\n",
      "   delay_days  \n",
      "0    7.070613  \n",
      "1    9.760208  \n",
      "2    4.841516  \n",
      "3    3.049977  \n",
      "4    4.008241  \n",
      "Database connection closed.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.Sellers generating revenue over 100,000 Real via Olist (without considering the date range issue for the latest date for order_status as the latest date in the database)",
   "id": "86a48f30ef5d9113"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Explanation of the Query\n",
    "1. **Revenue Calculation**: The query calculates the total revenue generated by each seller by summing the prices of the products they sold. It uses the `order_items` table to get the price of each product and the `orders` table to filter only the orders that are delivered (`order_status = 'delivered'`).\n",
    "2. **Common Key**: The common key between the `order_items` and `sellers` tables is the `seller_id`, which is used to join the two tables and retrieve additional information about the sellers.\n",
    "3. **Filtering Criteria**: The query filters the sellers based on the total revenue generated, selecting only those sellers who have generated over 100,000 Real.\n",
    "4. **Result Columns**: The final result includes the `seller_id`, `seller_zip_code_prefix`, and `total_revenue` columns for the selected sellers.\n",
    "5. **Data Loading**: The query result is loaded into a pandas DataFrame for further analysis and display.\n",
    "6. **Display**: The first few rows of the resulting DataFrame are displayed to show the sellers who have generated revenue over 100,000 Real.\n",
    "7. **Context**: The query considers the date range issue and provides additional information if no data is available due to older dates in the database."
   ],
   "id": "a757012e6a77489d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T16:56:21.000745Z",
     "start_time": "2024-07-24T16:56:19.690481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# Relative path to the database\n",
    "db_path = os.path.join('..', 'data', 'olist.db')\n",
    "\n",
    "# Function to execute SQL queries and return DataFrames\n",
    "def execute_query(query):\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        return pd.read_sql(query, conn)\n",
    "\n",
    "# SQL query for sellers generating revenue over 100,000 Real\n",
    "query_revenue_sellers = \"\"\"\n",
    "WITH Revenue AS (\n",
    "    SELECT\n",
    "        i.seller_id,\n",
    "        SUM(i.price) AS total_revenue\n",
    "    FROM order_items AS i\n",
    "    JOIN orders AS o ON i.order_id = o.order_id\n",
    "    WHERE o.order_status = 'delivered'\n",
    "    GROUP BY i.seller_id\n",
    ")\n",
    "SELECT s.seller_id, s.seller_zip_code_prefix, r.total_revenue\n",
    "FROM Revenue AS r\n",
    "JOIN sellers AS s ON r.seller_id = s.seller_id\n",
    "WHERE r.total_revenue > 100000;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and load data into a DataFrame\n",
    "data_revenue_sellers = execute_query(query_revenue_sellers)\n",
    "print(\"DataFrame: revenue_sellers\")\n",
    "print(data_revenue_sellers.shape)\n",
    "print(data_revenue_sellers[[\"seller_id\", \"total_revenue\"]])  # Display the first few rows of the result\n",
    "print()\n"
   ],
   "id": "210c04c782ad1f36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame: revenue_sellers\n",
      "(17, 3)\n",
      "                           seller_id  total_revenue\n",
      "0   7e93a43ef30c4f03f38b393420bc753a      165981.49\n",
      "1   7d13fca15225358621be4086e1eb0964      112436.18\n",
      "2   955fee9216a65b617aa5c0531780ce60      131836.71\n",
      "3   1f50f920176fa81dab994f9023523100      106655.71\n",
      "4   fa1c13f2614d7b5c4749cbc52fecda94      190917.14\n",
      "5   6560211a19b47992c3666cc44a7e94c0      120702.83\n",
      "6   53243585a1d6dc2643021fd1853d8905      217940.44\n",
      "7   7c67e1448b00f6e969d365cea6b010ab      186570.05\n",
      "8   cc419e0650a3c5ba77189a1882b7556a      101090.96\n",
      "9   da8622b14eb17ae2831f4ac5b9dab84a      159816.87\n",
      "10  620c87c171fb2a6dd6e8bb4dec959fc6      112461.50\n",
      "11  7a67c85e85bb2ce8582c35f2203ad736      139658.69\n",
      "12  5dceca129747e92ff8ef7a997dc4f8ca      111126.73\n",
      "13  4a3ca9315b744ce9f8e9374361493884      196882.12\n",
      "14  4869f7a5dfa277a7dca6462dcf3b52b2      226987.93\n",
      "15  1025f0e2d44d7041d6cf58b6550e0bfa      138208.56\n",
      "16  46dc3b2cc0980fb8ec44634e21d2718e      122811.38\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "53616b304ca5fbae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Who are the new sellers (less than 3 months of seniority) who are already highly engaged with the platform (having already sold more than 30 products) without considering the date range issue (latest date for order_purchase_timestamp as it is in the database)",
   "id": "8abcac481271fc10"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Explanation of the Query\n",
    "1. **New Sellers**: The query identifies new sellers who have been active on the platform for less than 90 days. It calculates the seller's seniority based on the date of their first order.\n",
    "2. **Highly Engaged Sellers**: The query filters the new sellers who have already sold more than 30 products, indicating high engagement with the platform.\n",
    "3. **Common Table Expressions (CTEs)**: The query uses two Common Table Expressions (CTEs) to first find the first order date for each seller and then calculate the total number of products sold by each seller.\n",
    "4. **Result Columns**: The final result includes the `seller_id` and `seller_zip_code_prefix` columns for the selected new sellers who are highly engaged with the platform.\n",
    "5. **Data Loading**: The query result is loaded into a pandas DataFrame for further analysis and display.\n",
    "6. **Display**: The first few rows of the resulting DataFrame are displayed to show the new sellers who are highly engaged with the platform.\n",
    "7. **Context**: The query considers the date range issue and provides additional information if no data is available due to older dates in the database."
   ],
   "id": "85add89c7680916e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T16:56:23.950397Z",
     "start_time": "2024-07-24T16:56:21.003273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Get today's date\n",
    "today = datetime.today().strftime('%Y-%m-%d')  # Format: YYYY-MM-DD\n",
    "\n",
    "# Relative path to the database\n",
    "db_path = os.path.join('..', 'data', 'olist.db')\n",
    "\n",
    "# Function to execute SQL queries and return DataFrames\n",
    "def execute_query(query):\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        return pd.read_sql(query, conn)\n",
    "\n",
    "# SQL query for New Sellers with More Than 30 Products Sold in the Last 3 Months (latest date for order_purchase_timestamp is the latest date in the database)\n",
    "query_new_sellers_final = \"\"\"\n",
    "WITH LatestDate AS (\n",
    "    SELECT MAX(order_purchase_timestamp) AS max_date\n",
    "    FROM orders\n",
    "),\n",
    "ThreeMonthsAgo AS (\n",
    "    SELECT datetime(MAX(order_purchase_timestamp), '-3 months') AS three_months_ago\n",
    "    FROM orders\n",
    "),\n",
    "SellerFirstOrder AS (\n",
    "    SELECT \n",
    "        i.seller_id,\n",
    "        MIN(o.order_purchase_timestamp) AS first_order_date\n",
    "    FROM order_items AS i\n",
    "    JOIN orders AS o ON i.order_id = o.order_id\n",
    "    GROUP BY i.seller_id\n",
    "),\n",
    "NewSellers AS (\n",
    "    SELECT \n",
    "        sfo.seller_id,\n",
    "        COUNT(i.order_item_id) AS total_products_sold\n",
    "    FROM SellerFirstOrder AS sfo\n",
    "    JOIN order_items AS i ON sfo.seller_id = i.seller_id\n",
    "    JOIN orders AS o ON i.order_id = o.order_id\n",
    "    WHERE \n",
    "        sfo.first_order_date >= (SELECT three_months_ago FROM ThreeMonthsAgo)\n",
    "        AND sfo.first_order_date <= (SELECT max_date FROM LatestDate)\n",
    "    GROUP BY sfo.seller_id\n",
    "    HAVING total_products_sold > 30\n",
    ")\n",
    "SELECT ns.seller_id, ns.total_products_sold\n",
    "FROM NewSellers AS ns\n",
    "JOIN sellers AS s ON ns.seller_id = s.seller_id;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the combined query and load data into a DataFrame\n",
    "data_new_sellers_final = execute_query(query_new_sellers_final)\n",
    "\n",
    "# Print the shape of the DataFrame\n",
    "num_sellers = data_new_sellers_final.shape[0]\n",
    "print(f\"DataFrame: new_sellers_final\")\n",
    "print(f\"Number of sellers: {num_sellers}\")\n",
    "print(f\"Shape of the resulting DataFrame: {data_new_sellers_final.shape}\")\n",
    "\n",
    "if data_new_sellers_final.empty:\n",
    "    print(f\"No data available. This may be due to the date range issue because the latest date in the database is {today}.\")\n",
    "else:\n",
    "    print(\"Query executed successfully.\")\n",
    "    print(data_new_sellers_final)  # Display the DataFrame\n"
   ],
   "id": "f58390873547038b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame: new_sellers_final\n",
      "Number of sellers: 2\n",
      "Shape of the resulting DataFrame: (2, 2)\n",
      "Query executed successfully.\n",
      "                          seller_id  total_products_sold\n",
      "0  d13e50eaa47b4cbe9eb81465865d8cfc                   69\n",
      "1  81f89e42267213cb94da7ddc301651da                   52\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "de5e15575058e861"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.Which are the 5 zip codes with more than 30 reviews that have the worst average review scores over the last 12 months considering the date range issue (latest date for review_creation_date as the latest date in the database)    ",
   "id": "f43d99a67da6e69a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Explanation of the Query\n",
    "1. **Average Review Scores**: The query calculates the average review scores for each zip code based on the reviews received over the last 12 months.\n",
    "2. **Filtering Criteria**: The query filters the zip codes based on the number of reviews received, selecting only those zip codes with more than 30 reviews.\n",
    "3. **Common Table Expression (CTE)**: The query uses a Common Table Expression (CTE) named `RecentReviews` to filter the reviews based on the review creation date within the last 12 months.\n",
    "4. **Result Columns**: The final result includes the `customer_zip_code_prefix` and `average_score` columns for the selected zip codes.\n",
    "5. **Data Loading**: The query result is loaded into a pandas DataFrame for further analysis and display.\n",
    "6. **Display**: The first few rows of the resulting DataFrame are displayed to show the 5 zip codes with the worst average review scores over the last 12 months.\n",
    "7. **Context**: The query considers the date range issue and provides additional information if no data is available due to older dates in the database."
   ],
   "id": "dd1a821ff9045c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Justification of Using Review Creation Date instead of Order Date   \n",
    "\n",
    "1. **Relevance of Reviews**: Reviews are often left after the products are received. Therefore, the review creation date is more directly tied to customer satisfaction and perceived quality of the service or product.\n",
    "2. **Time Elapsed Since Order**: There can be a significant lag between the order date (order_purchase_timestamp) and the review creation date, especially if delivery takes time or customers delay leaving a review.\n",
    "3. **Temporal Accuracy**: Using the review creation date provides a more precise and current measure of reviews left within the last 12 months.\n",
    "\n",
    "From a logical standpoint, the order_purchase_timestamp cannot be used as it does not accurately reflect the timing of customer feedback."
   ],
   "id": "342fcf9d9c630019"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T16:56:27.067608Z",
     "start_time": "2024-07-24T16:56:23.951908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Get today's date\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Relative path to the database\n",
    "db_path = os.path.join('..', 'data', 'olist.db')\n",
    "\n",
    "# Function to execute SQL queries and return DataFrames\n",
    "def execute_query(query):\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        return pd.read_sql(query, conn)\n",
    "\n",
    "# SQL query for the 5 zip codes with more than 30 reviews and the worst average review scores over the last 12 months \n",
    "# Review_creation_date is latest date in the database (more relevant for review analysis than order_purchase_timestamp)\n",
    "query_zip_codes_reviews = \"\"\"\n",
    "WITH LatestReviewDate AS (\n",
    "    SELECT MAX(review_creation_date) AS max_review_date\n",
    "    FROM order_reviews\n",
    "),\n",
    "OneYearAgo AS (\n",
    "    SELECT datetime(MAX(review_creation_date), '-12 months') AS one_year_ago\n",
    "    FROM order_reviews\n",
    "),\n",
    "RecentReviews AS (\n",
    "    SELECT \n",
    "        r.review_id,\n",
    "        r.review_score,\n",
    "        c.customer_zip_code_prefix,\n",
    "        r.review_creation_date\n",
    "    FROM order_reviews AS r\n",
    "    JOIN orders AS o ON r.order_id = o.order_id\n",
    "    JOIN customers AS c ON o.customer_id = c.customer_id\n",
    "    WHERE \n",
    "        r.review_creation_date >= (SELECT one_year_ago FROM OneYearAgo)\n",
    "        AND r.review_creation_date <= (SELECT max_review_date FROM LatestReviewDate)\n",
    "),\n",
    "ZipScores AS (\n",
    "    SELECT \n",
    "        customer_zip_code_prefix,\n",
    "        AVG(review_score) AS average_score,\n",
    "        COUNT(review_id) AS review_count\n",
    "    FROM RecentReviews\n",
    "    GROUP BY customer_zip_code_prefix\n",
    "    HAVING review_count > 30\n",
    ")\n",
    "SELECT \n",
    "    customer_zip_code_prefix,\n",
    "    average_score\n",
    "FROM ZipScores\n",
    "ORDER BY average_score ASC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the combined query and load data into a DataFrame\n",
    "data_zip_codes_reviews = execute_query(query_zip_codes_reviews)\n",
    "\n",
    "# Print the shape of the DataFrame and display the results\n",
    "print(\"DataFrame: zip_codes_reviews\")\n",
    "num_zip_codes = data_zip_codes_reviews.shape[0]\n",
    "print(f\"Number of zip codes: {num_zip_codes}\")\n",
    "print(f\"Shape of the resulting DataFrame: {data_zip_codes_reviews.shape}\")\n",
    "\n",
    "if data_zip_codes_reviews.empty:\n",
    "    most_recent_date_query = \"\"\"\n",
    "    SELECT MAX(review_creation_date) AS most_recent_review_date\n",
    "    FROM order_reviews;\n",
    "    \"\"\"\n",
    "    data_recent_review_date = execute_query(most_recent_date_query)\n",
    "    most_recent_date = data_recent_review_date['most_recent_review_date'].iloc[0]\n",
    "    most_recent_date = datetime.strptime(most_recent_date, '%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"No data available. This may be due to the date range issue because the most recent review date in the database is {most_recent_date}.\")\n",
    "else:\n",
    "    print(\"Query executed successfully.\")\n",
    "    print(data_zip_codes_reviews)  # Display the DataFrame\n"
   ],
   "id": "66cacb7be3af33e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame: zip_codes_reviews\n",
      "Number of zip codes: 5\n",
      "Shape of the resulting DataFrame: (5, 2)\n",
      "Query executed successfully.\n",
      "   customer_zip_code_prefix  average_score\n",
      "0                     22753       2.867925\n",
      "1                     22723       3.000000\n",
      "2                     28893       3.125000\n",
      "3                     22770       3.184211\n",
      "4                     13056       3.272727\n"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
